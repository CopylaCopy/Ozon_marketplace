{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c6e4d996",
   "metadata": {
    "cellId": "bls132imi3lk984l5611l"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "31f7b1b8",
   "metadata": {
    "cellId": "ecgc500ig4e84c0e08wi96"
   },
   "outputs": [],
   "source": [
    "# gdown.download('https://drive.google.com/file/d/17NBXx6l_6znStM52RJOKKKlxnHigavzq/view', fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "04bb1c32",
   "metadata": {
    "cellId": "wfvjmfdiopmgq06lqsi97g"
   },
   "outputs": [],
   "source": [
    "# tar -xvzf hackathon_objects.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7186364",
   "metadata": {
    "cellId": "s3787kdzasvahec8kf73r"
   },
   "outputs": [],
   "source": [
    "goods_data = pd.read_parquet('../datasets/train_data.parquet')\n",
    "\n",
    "goods_pairs = pd.read_parquet('../datasets/train_pairs_w_target.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82e1c9a",
   "metadata": {
    "cellId": "e8ysdi4b9cgil23ozi6ndh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51197862</td>\n",
       "      <td>51198054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53062686</td>\n",
       "      <td>536165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53602615</td>\n",
       "      <td>587809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53888651</td>\n",
       "      <td>89598677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56930698</td>\n",
       "      <td>551526166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  variantid1  variantid2\n",
       "0     0.0    51197862    51198054\n",
       "1     1.0    53062686   536165289\n",
       "2     1.0    53602615   587809782\n",
       "3     1.0    53888651    89598677\n",
       "4     0.0    56930698   551526166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goods_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf33b77",
   "metadata": {
    "cellId": "bx0pomb8jeuy85ea89zip"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid</th>\n",
       "      <th>characteristic_attributes_mapping</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>color_parsed</th>\n",
       "      <th>pic_embeddings_resnet_v1</th>\n",
       "      <th>main_pic_embeddings_resnet_v1</th>\n",
       "      <th>name_bert_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51195767</td>\n",
       "      <td>{\"85\":[\"Партнер-Электро\"],\"8229\":[\"Удлинитель ...</td>\n",
       "      <td>Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[оранжевый]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.04603629, 0.18839523, -0.09973055, -0.6636...</td>\n",
       "      <td>[-0.47045058, 0.67237014, 0.48984158, -0.54485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51196903</td>\n",
       "      <td>{\"85\":[\"TDM Electric\"],\"8229\":[\"Удлинитель быт...</td>\n",
       "      <td>Колодка TDM Electric пятиместная без заземлени...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[белый]</td>\n",
       "      <td>[[0.42044494, -0.33794826, -0.037247024, 0.165...</td>\n",
       "      <td>[[0.16211876, -0.4455993, 0.6131705, 0.5954206...</td>\n",
       "      <td>[-0.48503304, 0.6264443, 0.6406273, -0.4696772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52061880</td>\n",
       "      <td>{\"85\":[\"MINAMOTO\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейка литиевая CR 1/3N 3V (CR11108) Minamo...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.66729844, -0.023996592, 0.42721167, 0.0205...</td>\n",
       "      <td>[[-0.8638098, -0.1625915, -0.034600798, 0.1337...</td>\n",
       "      <td>[-0.15832633, 0.44736174, 0.31883216, -0.55559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52067481</td>\n",
       "      <td>{\"85\":[\"Duracell\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейки DURACELL Ultra Power AA (LR6), 4 шт</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.3516068, 0.6306597, 0.80962396, -0.0104141...</td>\n",
       "      <td>[[-0.26286322, 0.22858405, 0.4346232, 0.023486...</td>\n",
       "      <td>[-0.42703134, 0.16898727, 0.53922343, -0.53523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52610752</td>\n",
       "      <td>{\"85\":[\"HP\"],\"8229\":[\"Картридж\"],\"5708\":[\"для ...</td>\n",
       "      <td>Картридж лазерный HP 12A Q2612A черный для LJ ...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Расходн...</td>\n",
       "      <td>[черный, чер]</td>\n",
       "      <td>[[-0.009966308, 0.70965785, 0.10790472, -0.411...</td>\n",
       "      <td>[[0.09032486, 0.74205226, 0.30355096, -0.04755...</td>\n",
       "      <td>[-0.4892143, 0.47568643, 0.6505941, -0.4106509...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variantid                  characteristic_attributes_mapping  \\\n",
       "0   51195767  {\"85\":[\"Партнер-Электро\"],\"8229\":[\"Удлинитель ...   \n",
       "1   51196903  {\"85\":[\"TDM Electric\"],\"8229\":[\"Удлинитель быт...   \n",
       "2   52061880  {\"85\":[\"MINAMOTO\"],\"8229\":[\"Батарейка\"],\"5111\"...   \n",
       "3   52067481  {\"85\":[\"Duracell\"],\"8229\":[\"Батарейка\"],\"5111\"...   \n",
       "4   52610752  {\"85\":[\"HP\"],\"8229\":[\"Картридж\"],\"5708\":[\"для ...   \n",
       "\n",
       "                                                name  \\\n",
       "0  Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...   \n",
       "1  Колодка TDM Electric пятиместная без заземлени...   \n",
       "2  Батарейка литиевая CR 1/3N 3V (CR11108) Minamo...   \n",
       "3      Батарейки DURACELL Ultra Power AA (LR6), 4 шт   \n",
       "4  Картридж лазерный HP 12A Q2612A черный для LJ ...   \n",
       "\n",
       "                                          categories   color_parsed  \\\n",
       "0  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...    [оранжевый]   \n",
       "1  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...        [белый]   \n",
       "2  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...           None   \n",
       "3  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...           None   \n",
       "4  {\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Расходн...  [черный, чер]   \n",
       "\n",
       "                            pic_embeddings_resnet_v1  \\\n",
       "0                                               None   \n",
       "1  [[0.42044494, -0.33794826, -0.037247024, 0.165...   \n",
       "2  [[0.66729844, -0.023996592, 0.42721167, 0.0205...   \n",
       "3  [[0.3516068, 0.6306597, 0.80962396, -0.0104141...   \n",
       "4  [[-0.009966308, 0.70965785, 0.10790472, -0.411...   \n",
       "\n",
       "                       main_pic_embeddings_resnet_v1  \\\n",
       "0  [[0.04603629, 0.18839523, -0.09973055, -0.6636...   \n",
       "1  [[0.16211876, -0.4455993, 0.6131705, 0.5954206...   \n",
       "2  [[-0.8638098, -0.1625915, -0.034600798, 0.1337...   \n",
       "3  [[-0.26286322, 0.22858405, 0.4346232, 0.023486...   \n",
       "4  [[0.09032486, 0.74205226, 0.30355096, -0.04755...   \n",
       "\n",
       "                                        name_bert_64  \n",
       "0  [-0.47045058, 0.67237014, 0.48984158, -0.54485...  \n",
       "1  [-0.48503304, 0.6264443, 0.6406273, -0.4696772...  \n",
       "2  [-0.15832633, 0.44736174, 0.31883216, -0.55559...  \n",
       "3  [-0.42703134, 0.16898727, 0.53922343, -0.53523...  \n",
       "4  [-0.4892143, 0.47568643, 0.6505941, -0.4106509...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goods_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a546c9",
   "metadata": {
    "cellId": "yk5wh4mhrz67saw80ojo6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04603629"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goods_data['main_pic_embeddings_resnet_v1'][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785eb8b",
   "metadata": {
    "cellId": "un7g4kr0qpd0tmhg5cztn"
   },
   "outputs": [],
   "source": [
    "def symm_pairs(df):\n",
    "    # todo: complete cliques of goods\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    cols = [\"variantid1\", \"variantid2\"]\n",
    "    for c in cols:\n",
    "        if c not in df2.columns:\n",
    "            raise UserWarning\n",
    "    df2 = df2.rename(columns={cols[0]: cols[1], cols[1]: cols[0]})\n",
    "    return pd.concat([df, df2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4340bd",
   "metadata": {
    "cellId": "1kwhyiuyzyerhlxq9l94hm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, original_dataset, pairs_dataset, embedding_columns):\n",
    "        self.original_dataset = original_dataset.set_index('variantid')\n",
    "        self.pairs_dataset = pairs_dataset\n",
    "        self.embedding_columns = embedding_columns\n",
    "        self.dataset = None\n",
    "        self.prepare_dataset()\n",
    "        \n",
    "\n",
    "    def prepare_dataset(self,):\n",
    "        neg_pairs =  self.pairs_dataset[ self.pairs_dataset.target ==0.].groupby('variantid1').variantid2.apply(lambda x: list(x)).to_frame()\n",
    "        pos_pairs =  self.pairs_dataset[ self.pairs_dataset.target ==1.].groupby('variantid1').variantid2.apply(lambda x: list(x)).to_frame()\n",
    "        self.dataset = pos_pairs.merge(neg_pairs, how = 'outer', left_index = True, right_index = True, indicator = True, suffixes = ['_pos', '_neg'])\n",
    "        sol = pd.Series(np.where(self.dataset.variantid2_pos.notnull(), self.dataset.variantid2_pos, pd.Series(self.dataset.index).apply(lambda x: [x])))\n",
    "        self.dataset['variantid2_pos'] = sol.set_axis(self.dataset.index)\n",
    "        ld = pd.Series(self.dataset.index).sample(frac = 1).apply(lambda x: [x])\n",
    "        sol = pd.Series(np.where(self.dataset.variantid2_neg.notnull(), self.dataset.variantid2_neg, ld))\n",
    "        self.dataset['variantid2_neg'] = sol.set_axis(self.dataset.index)\n",
    "        self.dataset = self.dataset.reset_index()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_idx = self.dataset.loc[index].variantid1\n",
    "        positive_idx = self.dataset.loc[index].variantid2_pos\n",
    "        negative_idx = self.dataset.loc[index].variantid2_neg\n",
    "        if len(positive_idx)>1:\n",
    "            val = np.random.choice(len(positive_idx), 1)[0]\n",
    "            positive_idx = positive_idx[val]\n",
    "        else:\n",
    "            positive_idx = positive_idx[0]\n",
    "        if len(negative_idx)>1:\n",
    "            val = np.random.choice(len(negative_idx), 1)[0]\n",
    "            negative_idx = negative_idx[val]\n",
    "        else:\n",
    "            negative_idx = negative_idx[0]\n",
    "        original_data = torch.cat([torch.tensor(self.original_dataset.loc[original_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[original_idx]['name_bert_64'])], axis = 0)\n",
    "        positive_pair = torch.cat([torch.tensor(self.original_dataset.loc[positive_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[positive_idx]['name_bert_64'])], axis =0)\n",
    "        negative_pair = torch.cat([torch.tensor(self.original_dataset.loc[negative_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[negative_idx]['name_bert_64'])], axis = 0)\n",
    "        return original_data, positive_pair, negative_pair, original_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)-1\n",
    "\n",
    "    # def get_embeddings(self, index):\n",
    "    #     embeddings = []\n",
    "    #     for column in self.embedding_columns:\n",
    "    #         embedding = self.original_dataset[column].iloc[index]\n",
    "    #         if embedding.shape[0] == 1:\n",
    "    #             embedding = embedding[0]\n",
    "    #         embeddings.append(embedding)\n",
    "    #     return torch.tensor(np.concatenate(embeddings))\n",
    "\n",
    "    # def find_positive_pair(self, original_id):\n",
    "    #     positive_pairs = self.pairs_dataset[self.pairs_dataset[\"target\"] == 1]\n",
    "    #     matching_pairs = positive_pairs[(positive_pairs[\"variantid1\"] == original_id)]\n",
    "\n",
    "    #     if len(matching_pairs) > 0:\n",
    "    #         # Randomly choose a positive pair if multiple pairs are found\n",
    "    #         chosen_pair = matching_pairs.sample(1)\n",
    "\n",
    "    #         # Get the ID of the other data point in the pair\n",
    "    #         pair_id = chosen_pair[\"variantid2\"].values[0]\n",
    "\n",
    "    #         # Retrieve the corresponding data from the original dataset\n",
    "    #         positive_row = self.get_embeddings(\n",
    "    #             self.original_dataset[\n",
    "    #                 self.original_dataset[\"variantid\"] == pair_id\n",
    "    #             ].index[0]\n",
    "    #         )\n",
    "\n",
    "    #         return positive_row\n",
    "\n",
    "    #     # Return original data if positive pair is not found\n",
    "    #     original_row = self.get_embeddings(\n",
    "    #         self.original_dataset[\n",
    "    #             self.original_dataset[\"variantid\"] == original_id\n",
    "    #         ].index[0]\n",
    "    #     )\n",
    "    #     return original_row\n",
    "\n",
    "    # def find_negative_pair(self, original_id):\n",
    "    #     negative_pairs = self.pairs_dataset[self.pairs_dataset[\"target\"] == 0]\n",
    "    #     matching_pairs = negative_pairs[(negative_pairs[\"variantid1\"] == original_id)]\n",
    "\n",
    "    #     if len(matching_pairs) > 0:\n",
    "    #         # Randomly choose a positive pair if multiple pairs are found\n",
    "    #         chosen_pair = matching_pairs.sample(1)\n",
    "\n",
    "    #         # Get the ID of the other data point in the pair\n",
    "    #         pair_id = chosen_pair[\"variantid2\"].values[0]\n",
    "\n",
    "    #         # Retrieve the corresponding data from the original dataset\n",
    "    #         negative_row = self.get_embeddings(\n",
    "    #             self.original_dataset[\n",
    "    #                 self.original_dataset[\"variantid\"] == pair_id\n",
    "    #             ].index[0]\n",
    "    #         )\n",
    "\n",
    "    #         return negative_row\n",
    "\n",
    "    #     # Return random data if positive pair is not found\n",
    "    #     random_row = self.get_embeddings(random.choice(self.original_dataset.index))\n",
    "    #     return random_row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686bdb8b",
   "metadata": {
    "cellId": "3tmtu33k29xdruqfbz2rac",
    "execution_id": "80fa1605-175e-411e-a81a-190708cc061f"
   },
   "source": [
    "# Actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e4bcd",
   "metadata": {
    "cellId": "e66sob5skeokmuldwzmmf"
   },
   "outputs": [],
   "source": [
    "symm_goods_pairs = symm_pairs(goods_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8649db5",
   "metadata": {
    "cellId": "otnmuau4n4qwqyw3z0rh29"
   },
   "outputs": [],
   "source": [
    "pos_pairs = symm_goods_pairs[symm_goods_pairs.target ==1].groupby('variantid1').variantid2.apply(lambda x: list(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85d576",
   "metadata": {
    "cellId": "i3dmg94zlqipj2x6sk1u3c"
   },
   "outputs": [],
   "source": [
    "#checking if lists contain duplicates\n",
    "pos_pairs.variantid2.apply(lambda x: len(x) !=len(set(x))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea394d7",
   "metadata": {
    "cellId": "s96pet1tpvxcign8kbos"
   },
   "outputs": [],
   "source": [
    "# добавить все симметричные positive pairs\n",
    "pos_pairs.variantid2.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a7478",
   "metadata": {
    "cellId": "1bml8e8n2hkepvpwr99isl"
   },
   "outputs": [],
   "source": [
    "embedding_columns = ['main_pic_embeddings_resnet_v1', 'name_bert_64']\n",
    "\n",
    "contrastive_dataset = ContrastiveDataset(goods_data, symm_goods_pairs, embedding_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a4620",
   "metadata": {
    "cellId": "s4fwg9p204n8sjuzrk1z02"
   },
   "outputs": [],
   "source": [
    "contrastive_dataloader = DataLoader(contrastive_dataset, batch_size=128, shuffle=False, drop_last= True)\n",
    "next(iter(contrastive_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e497d",
   "metadata": {
    "cellId": "3cun742d9ar3c3ufu877pt"
   },
   "outputs": [],
   "source": [
    "yt[0].shape, yt[1].shape, yt[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad1e3e",
   "metadata": {
    "cellId": "8hmealx9wh946wmkeqqznp",
    "execution_id": "4c11f772-d5dc-440d-be92-b9930289b0ab"
   },
   "source": [
    "# Basic train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020045d7",
   "metadata": {
    "cellId": "ay38wirpqjkd7ofwk5wgo"
   },
   "outputs": [],
   "source": [
    "contrastive_dataset.dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f89a63",
   "metadata": {
    "cellId": "v3sv6t44b74rjsewq93wo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3f565f20",
   "metadata": {
    "cellId": "hftt4a973j5hxwbsb6hmd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e724089",
   "metadata": {
    "cellId": "og2gft5os44sped1le5br"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, embedding_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    distance_positive = torch.norm(anchor - positive, dim=1)\n",
    "    distance_negative = torch.norm(anchor - negative, dim=1)\n",
    "    loss = torch.clamp(distance_positive - distance_negative + margin, min=0.0).mean()\n",
    "    return loss\n",
    "\n",
    "# Example parameters\n",
    "input_size = 192\n",
    "hidden_size = 64\n",
    "embedding_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create an instance of the model\n",
    "model = ContrastiveModel(input_size, hidden_size, embedding_size).to(device)\n",
    "\n",
    "# Define the optimizer and the loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for original_data, positive_pair, negative_pair, _ in tqdm(contrastive_dataloader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        anchor = model(original_data.to(device))\n",
    "        positive = model(positive_pair.to(device))\n",
    "        negative = model(negative_pair.to(device))\n",
    "        \n",
    "        # Compute the triplet loss\n",
    "        loss = triplet_loss(anchor, positive, negative)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "   #     print(loss.item())\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(contrastive_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca53b3",
   "metadata": {
    "cellId": "tn62zsqm6jji9xbbq93je"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'contrastive_ozon.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5e3dd",
   "metadata": {
    "cellId": "13e01eam7vpcthi0zaphyes"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    y_idxs = []\n",
    "    y_embed = []\n",
    "    for orig, _, _, idx in tqdm(dataloader):\n",
    "        embed = model(orig.to(device))\n",
    "        y_idxs.extend([i.detach().cpu().item() for i in idx])\n",
    "        y_embed.extend([[j.item() for j in i.detach().cpu()] for i in embed])\n",
    "    return y_idxs, y_embed\n",
    "\n",
    "y_idxs, y_embed = predict(model, contrastive_dataloader)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee300f0",
   "metadata": {
    "cellId": "9orsf3i14eqo52bde0ml3c"
   },
   "outputs": [],
   "source": [
    "embed = pd.DataFrame({'variant': y_idxs, 'embed': y_embed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a4e799",
   "metadata": {
    "cellId": "g3o1xq22itpmmshc6un34i"
   },
   "outputs": [],
   "source": [
    "classif = goods_pairs.merge(embed, left_on = 'variantid1', right_on = 'variant', how = 'left', suffixes = ['', '_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea322629",
   "metadata": {
    "cellId": "37zv19v54l21bl3xqk224l"
   },
   "outputs": [],
   "source": [
    "classif = classif.merge(embed, left_on = 'variantid2', right_on='variant', how = 'left', suffixes = ['', '_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f03ace",
   "metadata": {
    "cellId": "d3pc3bb7jn3k90ok69kau"
   },
   "outputs": [],
   "source": [
    "classif.drop(['variant', 'variant_2'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd21200",
   "metadata": {
    "cellId": "pqon8v6l7p9gyjw16bjqfa"
   },
   "outputs": [],
   "source": [
    "classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26819d5",
   "metadata": {
    "cellId": "b64u7c87e6u48lonzzx3f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f540c4",
   "metadata": {
    "cellId": "mopn4qv5i8i1x3oronex"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497a2ce",
   "metadata": {
    "cellId": "9go079xfvtxuorqjpzu4e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_pic_features(main_pic_embeddings_1,\n",
    "                     main_pic_embeddings_2,\n",
    "                     percentiles):\n",
    "    \"\"\"Calculate distances percentiles for \n",
    "    pairwise pic distances. Percentiles are useful \n",
    "    when product has several pictures.\n",
    "    \"\"\"\n",
    "    \n",
    "    if main_pic_embeddings_1 is not None and main_pic_embeddings_2 is not None:     \n",
    "        dist_m = cosine_similarity(\n",
    "            np.array(main_pic_embeddings_1)[None, ...], np.array(main_pic_embeddings_2)[None, ...]\n",
    "        )\n",
    "    else:\n",
    "        dist_m = np.array([[-1]])\n",
    "\n",
    "    pair_features = []\n",
    "    pair_features += np.percentile(dist_m, percentiles).tolist()\n",
    "\n",
    "    return pair_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54b2b4",
   "metadata": {
    "cellId": "ut1e5u6qu2gluvld837tta"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "classif = classif.dropna()\n",
    "get_pic_features_func = partial(\n",
    "    get_pic_features,\n",
    "    percentiles=[0, 25, 50]\n",
    ")\n",
    "classif[[\"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\"]] = (\n",
    "    classif[[\"embed\", \"embed_2\"]].apply(\n",
    "        lambda x: pd.Series(get_pic_features_func(*x)), axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59979f",
   "metadata": {
    "cellId": "i1lb4nsuj68dx3cmveqqq"
   },
   "outputs": [],
   "source": [
    "classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa4806",
   "metadata": {
    "cellId": "oeawc6hyl3il3gk2oqpyq"
   },
   "outputs": [],
   "source": [
    "classif = classif.merge(goods_data[['variantid', 'categories']], left_on = 'variantid1', right_on = 'variantid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc894c3b",
   "metadata": {
    "cellId": "bmibmktlf6uemkdk0j12o7"
   },
   "outputs": [],
   "source": [
    "classif[\"cat3\"] = classif[\"categories\"].apply(lambda x: json.loads(x)[\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b708b0e",
   "metadata": {
    "cellId": "ovqvub872bfhivgi4m9e69"
   },
   "outputs": [],
   "source": [
    "cat3_counts = classif[\"cat3\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8d5e8",
   "metadata": {
    "cellId": "9la25mcu27ggjqsjoflb7i"
   },
   "outputs": [],
   "source": [
    "classif[\"cat3_grouped\"] = classif[\"cat3\"].apply(lambda x: x if cat3_counts[x] > 1000 else \"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc311ff8",
   "metadata": {
    "cellId": "ydwdup5fpkqu3geo3fa04"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(\n",
    "    classif[['target', \"variantid1\", \"variantid2\", 'pic_dist_0_perc', 'cat3_grouped']], \n",
    "    test_size=0.1, random_state=42, stratify=classif[[\"target\", \"cat3_grouped\"]]\n",
    ")\n",
    "\n",
    "y_test = X_test[[\"target\", \"variantid1\", \"variantid2\" ]]\n",
    "X_test = X_test.drop([\"target\"], axis=1)\n",
    "\n",
    "y_train = X_train[\"target\"]\n",
    "\n",
    "X_train = X_train.drop([\"target\", \"variantid1\", \"variantid2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582e5cb",
   "metadata": {
    "cellId": "poaoj9o5eeeorfxgq5ort"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e208ddb6",
   "metadata": {
    "cellId": "a13xa6w8h3lhncspvnagcj"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier()\n",
    "\n",
    "model.fit(\n",
    "    X_train[['pic_dist_0_perc']], y_train,\n",
    "    plot=True,\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50,\n",
    "    metric_period=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422d27ad",
   "metadata": {
    "cellId": "1k7a8yxdp81jvpz0qnh02a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def pr_auc_macro(\n",
    "    target_df: pd.DataFrame,\n",
    "    predictions_df: pd.DataFrame,\n",
    "    prec_level: float = 0.75,\n",
    "    cat_column: str = \"cat3_grouped\"\n",
    ") -> float:\n",
    "    \n",
    "    df = target_df.merge(predictions_df, on=[\"variantid1\", \"variantid2\"])\n",
    "    \n",
    "    y_true = df[\"target\"]\n",
    "    y_pred = df[\"scores\"]\n",
    "    categories = df[cat_column]\n",
    "    \n",
    "    weights = []\n",
    "    pr_aucs = []\n",
    "\n",
    "    unique_cats, counts = np.unique(categories, return_counts=True)\n",
    "\n",
    "    for i, category in enumerate(unique_cats):\n",
    "        cat_idx = np.where(categories == category)[0]\n",
    "        y_pred_cat = y_pred[cat_idx]\n",
    "        y_true_cat = y_true[cat_idx]\n",
    "\n",
    "        y, x, thr = precision_recall_curve(y_true_cat, y_pred_cat)\n",
    "        gt_prec_level_idx = np.where(y >= prec_level)[0]\n",
    "\n",
    "        try:\n",
    "            pr_auc_prec_level = auc(x[gt_prec_level_idx], y[gt_prec_level_idx])\n",
    "            if not np.isnan(pr_auc_prec_level):\n",
    "                pr_aucs.append(pr_auc_prec_level)\n",
    "                weights.append(counts[i] / len(categories))\n",
    "        except ValueError as err:\n",
    "            pr_aucs.append(0)\n",
    "            weights.append(0)\n",
    "    return np.average(pr_aucs, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f9c60",
   "metadata": {
    "cellId": "0y7u0wwjgcpj99muomn1emh"
   },
   "outputs": [],
   "source": [
    "X_test[\"scores\"] = model.predict_proba(X_test[['pic_dist_0_perc']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a735c65",
   "metadata": {
    "cellId": "69e7vct6nxvxf4iuwgh5ji"
   },
   "outputs": [],
   "source": [
    "pr_auc_macro_metr = pr_auc_macro(\n",
    "    target_df=y_test, \n",
    "    predictions_df=X_test,\n",
    "    prec_level=0.75,\n",
    "    cat_column=\"cat3_grouped\"\n",
    ")\n",
    "\n",
    "pr_auc_macro_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d710c",
   "metadata": {
    "cellId": "py1fw3spfpeqsnb7tkb37k"
   },
   "outputs": [],
   "source": [
    "#используется только одна картинка, можно делать positive pairs со всеми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aeefb3",
   "metadata": {
    "cellId": "mt4yz3g9o7lkrtj4j59xam"
   },
   "outputs": [],
   "source": [
    "X_test[\"scores\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624cebc",
   "metadata": {
    "cellId": "h1cf0dhqx4rnggk19u32"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "04a6e98d-b272-4bc0-9032-20ad0d86f1c3",
  "notebookPath": "ozon/Ozon_marketplace/ozon_zozon.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
