{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b38796ca",
   "metadata": {
    "cellId": "bls132imi3lk984l5611l"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "69544fdd",
   "metadata": {
    "cellId": "r3vbc4ynk2po00z35f03te"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd0b3a34",
   "metadata": {
    "cellId": "ecgc500ig4e84c0e08wi96"
   },
   "outputs": [],
   "source": [
    "# gdown.download('https://drive.google.com/file/d/17NBXx6l_6znStM52RJOKKKlxnHigavzq/view', fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98bd7d9d",
   "metadata": {
    "cellId": "wfvjmfdiopmgq06lqsi97g"
   },
   "outputs": [],
   "source": [
    "# tar -xvzf hackathon_objects.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69a07184",
   "metadata": {
    "cellId": "s3787kdzasvahec8kf73r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using datasphere folder\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "\n",
    "    goods_data = pd.read_parquet('../datasets/train_data.parquet')\n",
    "\n",
    "    goods_pairs = pd.read_parquet('../datasets/train_pairs_w_target.parquet')\n",
    "except FileNotFoundError:\n",
    "    print('Using datasphere folder')\n",
    "    \n",
    "    goods_data = pd.read_parquet('../../files/datasets/train_data.parquet')\n",
    "\n",
    "    goods_pairs = pd.read_parquet('../../files/datasets/train_pairs_w_target.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9b6153b",
   "metadata": {
    "cellId": "e8ysdi4b9cgil23ozi6ndh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>variantid1</th>\n",
       "      <th>variantid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51197862</td>\n",
       "      <td>51198054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53062686</td>\n",
       "      <td>536165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53602615</td>\n",
       "      <td>587809782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53888651</td>\n",
       "      <td>89598677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>56930698</td>\n",
       "      <td>551526166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  variantid1  variantid2\n",
       "0     0.0    51197862    51198054\n",
       "1     1.0    53062686   536165289\n",
       "2     1.0    53602615   587809782\n",
       "3     1.0    53888651    89598677\n",
       "4     0.0    56930698   551526166"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goods_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "781b8a2a",
   "metadata": {
    "cellId": "bx0pomb8jeuy85ea89zip"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid</th>\n",
       "      <th>characteristic_attributes_mapping</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>color_parsed</th>\n",
       "      <th>pic_embeddings_resnet_v1</th>\n",
       "      <th>main_pic_embeddings_resnet_v1</th>\n",
       "      <th>name_bert_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51195767</td>\n",
       "      <td>{\"85\":[\"Партнер-Электро\"],\"8229\":[\"Удлинитель ...</td>\n",
       "      <td>Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[оранжевый]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.04603629, 0.18839523, -0.09973055, -0.6636...</td>\n",
       "      <td>[-0.47045058, 0.67237014, 0.48984158, -0.54485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51196903</td>\n",
       "      <td>{\"85\":[\"TDM Electric\"],\"8229\":[\"Удлинитель быт...</td>\n",
       "      <td>Колодка TDM Electric пятиместная без заземлени...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[белый]</td>\n",
       "      <td>[[0.42044494, -0.33794826, -0.037247024, 0.165...</td>\n",
       "      <td>[[0.16211876, -0.4455993, 0.6131705, 0.5954206...</td>\n",
       "      <td>[-0.48503304, 0.6264443, 0.6406273, -0.4696772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52061880</td>\n",
       "      <td>{\"85\":[\"MINAMOTO\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейка литиевая CR 1/3N 3V (CR11108) Minamo...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.66729844, -0.023996592, 0.42721167, 0.0205...</td>\n",
       "      <td>[[-0.8638098, -0.1625915, -0.034600798, 0.1337...</td>\n",
       "      <td>[-0.15832633, 0.44736174, 0.31883216, -0.55559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52067481</td>\n",
       "      <td>{\"85\":[\"Duracell\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейки DURACELL Ultra Power AA (LR6), 4 шт</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.3516068, 0.6306597, 0.80962396, -0.0104141...</td>\n",
       "      <td>[[-0.26286322, 0.22858405, 0.4346232, 0.023486...</td>\n",
       "      <td>[-0.42703134, 0.16898727, 0.53922343, -0.53523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52610752</td>\n",
       "      <td>{\"85\":[\"HP\"],\"8229\":[\"Картридж\"],\"5708\":[\"для ...</td>\n",
       "      <td>Картридж лазерный HP 12A Q2612A черный для LJ ...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Расходн...</td>\n",
       "      <td>[черный, чер]</td>\n",
       "      <td>[[-0.009966308, 0.70965785, 0.10790472, -0.411...</td>\n",
       "      <td>[[0.09032486, 0.74205226, 0.30355096, -0.04755...</td>\n",
       "      <td>[-0.4892143, 0.47568643, 0.6505941, -0.4106509...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variantid  ...                                       name_bert_64\n",
       "0   51195767  ...  [-0.47045058, 0.67237014, 0.48984158, -0.54485...\n",
       "1   51196903  ...  [-0.48503304, 0.6264443, 0.6406273, -0.4696772...\n",
       "2   52061880  ...  [-0.15832633, 0.44736174, 0.31883216, -0.55559...\n",
       "3   52067481  ...  [-0.42703134, 0.16898727, 0.53922343, -0.53523...\n",
       "4   52610752  ...  [-0.4892143, 0.47568643, 0.6505941, -0.4106509...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goods_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "880a5349",
   "metadata": {
    "cellId": "yk5wh4mhrz67saw80ojo6"
   },
   "outputs": [],
   "source": [
    "a = eval(goods_data['characteristic_attributes_mapping'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f031bd8c",
   "metadata": {
    "cellId": "ql52gxurc70xj79lsc35op"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CAT_85]: Партнер-Электро. [CAT_8229]: Удлинитель бытовой. [CAT_10096]: оранжевый. [CAT_5774]: Евровилка. [CAT_5739]: 220. [CAT_5776]: 10. [CAT_5778]: 10. [CAT_5777]: 2200. [CAT_5129]: Заземление. [CAT_5779]: IP44. [CAT_4383]: 1760. [CAT_7463]: 30. [CAT_4389]: Россия. '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dict_to_str(x):\n",
    "    ans = ''\n",
    "    for k in x.keys():\n",
    "        ans += f'{k}: '\n",
    "        try:\n",
    "            for i, elem in enumerate(x[k]):\n",
    "                if i != (len(x[k]) - 1):\n",
    "                    ans += f'{elem}, '\n",
    "                else:\n",
    "                    ans += f'{elem}. '\n",
    "        except ValueError:\n",
    "            print(x[k])\n",
    "            raise ValueError\n",
    "            break\n",
    "    return ans\n",
    "\n",
    "def preprocess_dict(x):\n",
    "    td = eval(x) # hehe\n",
    "    td_new = dict(zip([f'[CAT_{k}]'  for k in td.keys()], td.values()))\n",
    "    return dict_to_str(td_new)\n",
    "    \n",
    "preprocess_dict(goods_data['characteristic_attributes_mapping'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c65484ec",
   "metadata": {
    "cellId": "qhhrji6ow1ku0upe6ggi8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ca15ff172a492c940c67d83255c3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/457063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "goods_data['cat_proc'] = goods_data['characteristic_attributes_mapping'].progress_apply(preprocess_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd8081b9",
   "metadata": {
    "cellId": "z4m52766ad101ixabwoko"
   },
   "outputs": [],
   "source": [
    "goods_data['to_nlp_data'] = goods_data['name'] + goods_data['cat_proc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a48ceecb",
   "metadata": {
    "cellId": "jimmqy3fzklkczzqm8z34"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a5012a19a44778a6e4bc820ddaf1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c91a0b532042b9b18054fa114755e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6bee9cf5ca45bcbdb17b242dbd46d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0a97015ffb48ff97c641e7c687d1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a936ece",
   "metadata": {
    "cellId": "s1bqv0wry5re1b7k8b01m9"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    if type(examples) == str:\n",
    "        examples = [examples]\n",
    "    return tokenizer(\n",
    "        examples, \n",
    "        return_tensors='pt',\n",
    "        padding='max_length', \n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )['input_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e8516cc",
   "metadata": {
    "cellId": "01x7gnf7t30msefu6qfki4h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_emb = tokenize_function('Каждый охотник желает охоты')\n",
    "orig_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "beaf85b1",
   "metadata": {
    "cellId": "48wilbeipn5782ujvw9rt5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "488df05c",
   "metadata": {
    "cellId": "mutkazs4vzowd12frq6tf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9fac49402949699b86d2851164f579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_nlp_dataloader = DataLoader(goods_data['to_nlp_data'], batch_size = 32, shuffle=False, drop_last=False)\n",
    "embs = []\n",
    "for elem in tqdm(to_nlp_dataloader):\n",
    "    embs.append(tokenize_function(elem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b308b65",
   "metadata": {
    "cellId": "eavfwu1h8q736kfuub51t4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c5099804",
   "metadata": {
    "cellId": "8om8eoxutv9yer3ldquzw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([457063, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs = torch.cat(embs)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "242bd04e",
   "metadata": {
    "cellId": "g3s2oa1j3atwgmj9rofbxa"
   },
   "outputs": [],
   "source": [
    "#goods_data['to_nlp_data_tokenized'] = goods_data['to_nlp_data'].progress_apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "69fa1b14",
   "metadata": {
    "cellId": "uqt9a3uln7cm6i3myr0t7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ngoods_data = goods_data.drop(\\n    [\\n        'pic_embeddings_resnet_v1',\\n        'to_nlp_data'.\\n        'cat_proc',\\n        'name',\\n        'main_pic_embeddings_resnet_v1'\\n    ]\\n)\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "goods_data = goods_data.drop(\n",
    "    [\n",
    "        'pic_embeddings_resnet_v1',\n",
    "        'to_nlp_data'.\n",
    "        'cat_proc',\n",
    "        'name',\n",
    "        'main_pic_embeddings_resnet_v1'\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbf88c7a",
   "metadata": {
    "cellId": "tpa9kix8ykg52m8qtslve2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variantid</th>\n",
       "      <th>characteristic_attributes_mapping</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>color_parsed</th>\n",
       "      <th>pic_embeddings_resnet_v1</th>\n",
       "      <th>main_pic_embeddings_resnet_v1</th>\n",
       "      <th>name_bert_64</th>\n",
       "      <th>cat_proc</th>\n",
       "      <th>to_nlp_data</th>\n",
       "      <th>normal_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51195767</td>\n",
       "      <td>{\"85\":[\"Партнер-Электро\"],\"8229\":[\"Удлинитель ...</td>\n",
       "      <td>Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[оранжевый]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.04603629, 0.18839523, -0.09973055, -0.6636...</td>\n",
       "      <td>[-0.47045058, 0.67237014, 0.48984158, -0.54485...</td>\n",
       "      <td>[CAT_85]: Партнер-Электро. [CAT_8229]: Удлинит...</td>\n",
       "      <td>Удлинитель Партнер-Электро ПВС 2х0,75 ГОСТ,6A,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51196903</td>\n",
       "      <td>{\"85\":[\"TDM Electric\"],\"8229\":[\"Удлинитель быт...</td>\n",
       "      <td>Колодка TDM Electric пятиместная без заземлени...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Сетевые...</td>\n",
       "      <td>[белый]</td>\n",
       "      <td>[[0.42044494, -0.33794826, -0.037247024, 0.165...</td>\n",
       "      <td>[[0.16211876, -0.4455993, 0.6131705, 0.5954206...</td>\n",
       "      <td>[-0.48503304, 0.6264443, 0.6406273, -0.4696772...</td>\n",
       "      <td>[CAT_85]: TDM Electric. [CAT_8229]: Удлинитель...</td>\n",
       "      <td>Колодка TDM Electric пятиместная без заземлени...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52061880</td>\n",
       "      <td>{\"85\":[\"MINAMOTO\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейка литиевая CR 1/3N 3V (CR11108) Minamo...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.66729844, -0.023996592, 0.42721167, 0.0205...</td>\n",
       "      <td>[[-0.8638098, -0.1625915, -0.034600798, 0.1337...</td>\n",
       "      <td>[-0.15832633, 0.44736174, 0.31883216, -0.55559...</td>\n",
       "      <td>[CAT_85]: MINAMOTO. [CAT_8229]: Батарейка. [CA...</td>\n",
       "      <td>Батарейка литиевая CR 1/3N 3V (CR11108) Minamo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52067481</td>\n",
       "      <td>{\"85\":[\"Duracell\"],\"8229\":[\"Батарейка\"],\"5111\"...</td>\n",
       "      <td>Батарейки DURACELL Ultra Power AA (LR6), 4 шт</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Батарей...</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.3516068, 0.6306597, 0.80962396, -0.0104141...</td>\n",
       "      <td>[[-0.26286322, 0.22858405, 0.4346232, 0.023486...</td>\n",
       "      <td>[-0.42703134, 0.16898727, 0.53922343, -0.53523...</td>\n",
       "      <td>[CAT_85]: Duracell. [CAT_8229]: Батарейка. [CA...</td>\n",
       "      <td>Батарейки DURACELL Ultra Power AA (LR6), 4 шт[...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52610752</td>\n",
       "      <td>{\"85\":[\"HP\"],\"8229\":[\"Картридж\"],\"5708\":[\"для ...</td>\n",
       "      <td>Картридж лазерный HP 12A Q2612A черный для LJ ...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Расходн...</td>\n",
       "      <td>[черный, чер]</td>\n",
       "      <td>[[-0.009966308, 0.70965785, 0.10790472, -0.411...</td>\n",
       "      <td>[[0.09032486, 0.74205226, 0.30355096, -0.04755...</td>\n",
       "      <td>[-0.4892143, 0.47568643, 0.6505941, -0.4106509...</td>\n",
       "      <td>[CAT_85]: HP. [CAT_8229]: Картридж. [CAT_5708]...</td>\n",
       "      <td>Картридж лазерный HP 12A Q2612A черный для LJ ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457058</th>\n",
       "      <td>822394794</td>\n",
       "      <td>{\"85\":[\"Poco\"],\"8229\":[\"Смартфон\"],\"10096\":[\"с...</td>\n",
       "      <td>Смартфон Poco M5s 4/128Gb Grey 4/128 ГБ, серый</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Смартфо...</td>\n",
       "      <td>[grey, серый]</td>\n",
       "      <td>[[0.5289667, -0.8587297, 0.6250174, 0.10048234...</td>\n",
       "      <td>[[0.48594046, -0.8139478, -0.11380915, -0.3833...</td>\n",
       "      <td>[-0.56425023, 0.41288334, 0.5501014, -0.330675...</td>\n",
       "      <td>[CAT_85]: Poco. [CAT_8229]: Смартфон. [CAT_100...</td>\n",
       "      <td>Смартфон Poco M5s 4/128Gb Grey 4/128 ГБ, серый...</td>\n",
       "      <td>457058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457059</th>\n",
       "      <td>822409141</td>\n",
       "      <td>{\"85\":[\"vlp\"],\"8229\":[\"Чехол для смартфона\"],\"...</td>\n",
       "      <td>Чехол vlp Silicone с MagSafe для iPhone 14 Plu...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Чехол\",...</td>\n",
       "      <td>[black, черный]</td>\n",
       "      <td>[[-0.25175428, -0.5215634, 0.88485634, 0.72421...</td>\n",
       "      <td>[[0.22031438, -1.3273709, 0.80755866, 0.343482...</td>\n",
       "      <td>[-0.073415995, 0.39561644, 0.4324598, -0.63042...</td>\n",
       "      <td>[CAT_85]: vlp. [CAT_8229]: Чехол для смартфона...</td>\n",
       "      <td>Чехол vlp Silicone с MagSafe для iPhone 14 Plu...</td>\n",
       "      <td>457059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457060</th>\n",
       "      <td>822467917</td>\n",
       "      <td>{\"85\":[\"Acer\"],\"10096\":[\"зеленый\"],\"4460\":[\"От...</td>\n",
       "      <td>Ноутбук Acer Aspire A317-32-C3M5 (17.3\"/Intel...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Компьют...</td>\n",
       "      <td>[black, черный, зеленый]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.7038868, -0.2959186, -0.7599652, -0.354495...</td>\n",
       "      <td>[-0.631185, 0.3781632, 0.50562716, -0.65348136...</td>\n",
       "      <td>[CAT_85]: Acer. [CAT_10096]: зеленый. [CAT_446...</td>\n",
       "      <td>Ноутбук Acer Aspire A317-32-C3M5 (17.3\"/Intel...</td>\n",
       "      <td>457060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457061</th>\n",
       "      <td>822735361</td>\n",
       "      <td>{\"85\":[\"Syncwire\"],\"8229\":[\"Видео-кабель\"],\"10...</td>\n",
       "      <td>Кабель для видеонаблюдения (КВК) 2П 2х0,5 LV 1...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Кабели ...</td>\n",
       "      <td>[черный]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[0.47696507, 0.568993, -0.024000928, 0.038465...</td>\n",
       "      <td>[-0.47451174, 0.3448143, 0.6183864, -0.5403839...</td>\n",
       "      <td>[CAT_85]: Syncwire. [CAT_8229]: Видео-кабель. ...</td>\n",
       "      <td>Кабель для видеонаблюдения (КВК) 2П 2х0,5 LV 1...</td>\n",
       "      <td>457061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457062</th>\n",
       "      <td>822788409</td>\n",
       "      <td>{\"85\":[\"Cactus\"],\"8229\":[\"Картридж\"],\"5713\":[\"...</td>\n",
       "      <td>Комплект 4 шт, Картридж MAGENTA /M252/252N/252...</td>\n",
       "      <td>{\"1\": \"EPG\", \"2\": \"Электроника\", \"3\": \"Расходн...</td>\n",
       "      <td>[magenta]</td>\n",
       "      <td>None</td>\n",
       "      <td>[[-0.86843157, 1.0203247, 0.2533189, 0.7505697...</td>\n",
       "      <td>[-0.4799904, 0.6441519, 0.33473626, -0.6852920...</td>\n",
       "      <td>[CAT_85]: Cactus. [CAT_8229]: Картридж. [CAT_5...</td>\n",
       "      <td>Комплект 4 шт, Картридж MAGENTA /M252/252N/252...</td>\n",
       "      <td>457062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457063 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        variantid  ... normal_index\n",
       "0        51195767  ...            0\n",
       "1        51196903  ...            1\n",
       "2        52061880  ...            2\n",
       "3        52067481  ...            3\n",
       "4        52610752  ...            4\n",
       "...           ...  ...          ...\n",
       "457058  822394794  ...       457058\n",
       "457059  822409141  ...       457059\n",
       "457060  822467917  ...       457060\n",
       "457061  822735361  ...       457061\n",
       "457062  822788409  ...       457062\n",
       "\n",
       "[457063 rows x 11 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goods_data['normal_index'] = np.arange(goods_data.shape[0])\n",
    "goods_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4a39e",
   "metadata": {
    "cellId": "yqeybei7wa8e48xeuacxa",
    "execution_id": "d9510f4e-b32b-403c-8cbe-202e37cb6055"
   },
   "source": [
    "#  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bdcb205",
   "metadata": {
    "cellId": "un7g4kr0qpd0tmhg5cztn"
   },
   "outputs": [],
   "source": [
    "def symm_pairs(df):\n",
    "    # todo: complete cliques of goods\n",
    "    \n",
    "    df2 = df.copy()\n",
    "    cols = [\"variantid1\", \"variantid2\"]\n",
    "    for c in cols:\n",
    "        if c not in df2.columns:\n",
    "            raise UserWarning\n",
    "    df2 = df2.rename(columns={cols[0]: cols[1], cols[1]: cols[0]})\n",
    "    return pd.concat([df, df2]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bd60fe21",
   "metadata": {
    "cellId": "1kwhyiuyzyerhlxq9l94hm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, original_dataset, pairs_dataset, embedding_columns, data):\n",
    "        self.original_dataset = original_dataset.set_index('variantid')\n",
    "        self.pairs_dataset = pairs_dataset\n",
    "        self.embedding_columns = embedding_columns\n",
    "        self.dataset = None\n",
    "        self.data = data\n",
    "        self.prepare_dataset()\n",
    "        \n",
    "\n",
    "    def prepare_dataset(\n",
    "        self,\n",
    "    ):\n",
    "        neg_pairs = (\n",
    "            self.pairs_dataset[self.pairs_dataset.target == 0.0]\n",
    "            .groupby(\"variantid1\")\n",
    "            .variantid2.apply(lambda x: list(x))\n",
    "            .to_frame()\n",
    "        )\n",
    "        pos_pairs = (\n",
    "            self.pairs_dataset[self.pairs_dataset.target == 1.0]\n",
    "            .groupby(\"variantid1\")\n",
    "            .variantid2.apply(lambda x: list(x))\n",
    "            .to_frame()\n",
    "        )\n",
    "        self.dataset = pos_pairs.merge(\n",
    "            neg_pairs,\n",
    "            how=\"outer\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "            indicator=True,\n",
    "            suffixes=[\"_pos\", \"_neg\"],\n",
    "        )\n",
    "        sol = pd.Series(\n",
    "            np.where(\n",
    "                self.dataset.variantid2_pos.notnull(),\n",
    "                self.dataset.variantid2_pos,\n",
    "                pd.Series(self.dataset.index).apply(lambda x: [x]),\n",
    "            )\n",
    "        )\n",
    "        self.dataset[\"variantid2_pos\"] = sol.set_axis(self.dataset.index)\n",
    "        ld = pd.Series(self.dataset.index).sample(frac=1).apply(lambda x: [x])\n",
    "        sol = pd.Series(\n",
    "            np.where(self.dataset.variantid2_neg.notnull(), self.dataset.variantid2_neg, ld)\n",
    "        )\n",
    "        self.dataset[\"variantid2_neg\"] = sol.set_axis(self.dataset.index)\n",
    "        self.dataset = self.dataset.reset_index()\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_idx = self.dataset.loc[index].variantid1\n",
    "        positive_idx = self.dataset.loc[index].variantid2_pos\n",
    "        negative_idx = self.dataset.loc[index].variantid2_neg\n",
    "        if len(positive_idx)>1:\n",
    "            val = np.random.choice(len(positive_idx), 1)[0]\n",
    "            positive_idx = positive_idx[val]\n",
    "        else:\n",
    "            positive_idx = positive_idx[0]\n",
    "        if len(negative_idx)>1:\n",
    "            val = np.random.choice(len(negative_idx), 1)[0]\n",
    "            negative_idx = negative_idx[val]\n",
    "        else:\n",
    "            negative_idx = negative_idx[0]\n",
    "        \n",
    "        original_data = self.data[self.original_dataset.loc[original_idx]['normal_index']]\n",
    "        positive_pair = self.data[self.original_dataset.loc[positive_idx]['normal_index']]\n",
    "        negative_pair = self.data[self.original_dataset.loc[negative_idx]['normal_index']]\n",
    "        \n",
    "        '''\n",
    "        original_data = self.original_dataset.loc[original_idx]['to_nlp_data_tokenized']\n",
    "        #torch.cat([torch.tensor(self.original_dataset.loc[original_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[original_idx]['name_bert_64'])], axis = 0)\n",
    "        positive_pair = self.original_dataset.loc[positive_idx]['to_nlp_data_tokenized']\n",
    "        #torch.cat([torch.tensor(self.original_dataset.loc[positive_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[positive_idx]['name_bert_64'])], axis =0)\n",
    "        negative_pair = self.original_dataset.loc[negative_idx]['to_nlp_data_tokenized']\n",
    "        #torch.cat([torch.tensor(self.original_dataset.loc[negative_idx]['main_pic_embeddings_resnet_v1'][0]), torch.tensor(self.original_dataset.loc[negative_idx]['name_bert_64'])], axis = 0)\n",
    "        '''\n",
    "        \n",
    "        return original_data, positive_pair, negative_pair, original_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cdcfa",
   "metadata": {
    "cellId": "3tmtu33k29xdruqfbz2rac",
    "execution_id": "957adb09-1b11-4692-a292-4e4198c681f7"
   },
   "source": [
    "# Actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30a20097",
   "metadata": {
    "cellId": "e66sob5skeokmuldwzmmf"
   },
   "outputs": [],
   "source": [
    "symm_goods_pairs = symm_pairs(goods_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f84937e",
   "metadata": {
    "cellId": "t2mjnr0arhiu2offwu7hw9"
   },
   "outputs": [],
   "source": [
    "pos_pairs = symm_goods_pairs[symm_goods_pairs.target ==1].groupby('variantid1').variantid2.apply(lambda x: list(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d5aff42",
   "metadata": {
    "cellId": "nq941935hwaa54be4wuljc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variantid2\n",
       "False    216911\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if lists contain duplicates\n",
    "pos_pairs.variantid2.apply(lambda x: len(x) !=len(set(x))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9df1dc08",
   "metadata": {
    "cellId": "e0h54jur2jwejixn71y48g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variantid2\n",
       "1     189650\n",
       "2      18977\n",
       "3       3806\n",
       "4       1403\n",
       "5        734\n",
       "6        561\n",
       "7        380\n",
       "8        287\n",
       "9        247\n",
       "10       190\n",
       "11       166\n",
       "12       129\n",
       "13       115\n",
       "14        72\n",
       "15        55\n",
       "16        40\n",
       "17        24\n",
       "18        22\n",
       "20        15\n",
       "19        14\n",
       "21         6\n",
       "22         5\n",
       "25         3\n",
       "26         3\n",
       "23         2\n",
       "27         2\n",
       "24         2\n",
       "28         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# добавить все симметричные positive pairs\n",
    "pos_pairs.variantid2.str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70ff3369",
   "metadata": {
    "cellId": "1bml8e8n2hkepvpwr99isl"
   },
   "outputs": [],
   "source": [
    "embedding_columns = ['main_pic_embeddings_resnet_v1', 'name_bert_64']\n",
    "\n",
    "contrastive_dataset = ContrastiveDataset(goods_data, symm_goods_pairs, embedding_columns, embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78795cee",
   "metadata": {
    "cellId": "4q3ocxtdw3exkuiwhjpbac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78609403",
   "metadata": {
    "cellId": "s4fwg9p204n8sjuzrk1z02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_dataloader = DataLoader(contrastive_dataset, batch_size=2, shuffle=True, drop_last= True)\n",
    "next(iter(contrastive_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de0e96",
   "metadata": {
    "cellId": "8hmealx9wh946wmkeqqznp",
    "execution_id": "643dfed4-7664-441a-9156-ac7fdba346a0"
   },
   "source": [
    "# Basic train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c25daa",
   "metadata": {
    "cellId": "gkifm2i5zlil6n6mg5y71"
   },
   "outputs": [],
   "source": [
    "contrastive_dataset.dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9900eb1",
   "metadata": {
    "cellId": "v3sv6t44b74rjsewq93wo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "452b8287",
   "metadata": {
    "cellId": "hftt4a973j5hxwbsb6hmd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba449e93",
   "metadata": {
    "cellId": "og2gft5os44sped1le5br"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd09f38e86942909f54c127c9836897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459fba5e6c334e01bca5100483e88f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    distance_positive = torch.norm(anchor - positive, dim=1)\n",
    "    distance_negative = torch.norm(anchor - negative, dim=1)\n",
    "    loss = torch.clamp(distance_positive - distance_negative + margin, min=0.0).mean()\n",
    "    return loss\n",
    "\n",
    "# Example parameters\n",
    "input_size = 192\n",
    "hidden_size = 64\n",
    "embedding_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Create an instance of the model\n",
    "# model = ContrastiveModel(input_size, hidden_size, embedding_size).to(device)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased\", \n",
    "    num_labels=embedding_size\n",
    ").to(device)\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer and the loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71d3420a",
   "metadata": {
    "cellId": "wgn74ma5e645297ciywuw",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py:585: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n",
      "Failed to deserialize variable 'ans'. Run the following code to delete it:\n",
      "  del_datasphere_variables('ans')\n",
      "Traceback (most recent call last):\n",
      "  File \"/kernel/lib/python3.8/site-packages/ml_kernel/state/state_protocol.py\", line 283, in _load_component\n",
      "    value = unpickler.load()\n",
      "  File \"<string>\", line 7, in __init__\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/transformers/utils/generic.py\", line 246, in __post_init__\n",
      "    if other_fields_are_none and not is_tensor(first_field):\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/transformers/utils/generic.py\", line 86, in is_tensor\n",
      "    import tensorflow as tf\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\", line 46, in <module>\n",
      "    from tensorflow.python import data\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 97, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 353, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.experimental.ops import compression_ops\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 20, in <module>\n",
      "    from tensorflow.python.data.util import structure\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/structure.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.util import nest\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/nest.py\", line 40, in <module>\n",
      "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 28, in <module>\n",
      "    from tensorflow.python.framework import constant_op\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\", line 29, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 27, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py\", line 585, in <module>\n",
      "    np.object,\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/numpy/__init__.py\", line 305, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'object'.\n",
      "`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "ml_kernel.state.state_protocol.KernelStateProtocol.DeserializationException: ['ans']\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py:585: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n",
      "Failed to deserialize variable 'ans'. Run the following code to delete it:\n",
      "  del_datasphere_variables('ans')\n",
      "Traceback (most recent call last):\n",
      "  File \"/kernel/lib/python3.8/site-packages/ml_kernel/state/state_protocol.py\", line 283, in _load_component\n",
      "    value = unpickler.load()\n",
      "  File \"<string>\", line 7, in __init__\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/transformers/utils/generic.py\", line 246, in __post_init__\n",
      "    if other_fields_are_none and not is_tensor(first_field):\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/transformers/utils/generic.py\", line 86, in is_tensor\n",
      "    import tensorflow as tf\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py\", line 46, in <module>\n",
      "    from tensorflow.python import data\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/__init__.py\", line 25, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/__init__.py\", line 97, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/service/__init__.py\", line 353, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.experimental.ops import compression_ops\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\", line 20, in <module>\n",
      "    from tensorflow.python.data.util import structure\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/structure.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.util import nest\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/util/nest.py\", line 40, in <module>\n",
      "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/sparse_tensor.py\", line 28, in <module>\n",
      "    from tensorflow.python.framework import constant_op\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\", line 29, in <module>\n",
      "    from tensorflow.python.eager import execute\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 27, in <module>\n",
      "    from tensorflow.python.framework import dtypes\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py\", line 585, in <module>\n",
      "    np.object,\n",
      "  File \"/home/jupyter/.local/lib/python3.8/site-packages/numpy/__init__.py\", line 305, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'object'.\n",
      "`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "ml_kernel.state.state_protocol.KernelStateProtocol.DeserializationException: ['ans']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "'''\n",
    "with torch.no_grad():\n",
    "    orig, pos, neg, idx = next(iter(contrastive_dataloader))\n",
    "\n",
    "    ans = model(orig.to(device))\n",
    "    ans\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb958b93",
   "metadata": {
    "cellId": "nkb2zyscm9jo6wuujp8ck"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd18c4",
   "metadata": {
    "cellId": "mx8o4wjxasrl2qzgwjonr",
    "execution_id": "c8a480ac-1c3f-472e-bf46-db444e9c79f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cb71467c78541ac83d4cb4a868c4650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9308602482ab4296afe2b29fcb32bbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# Train loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for original_data, positive_pair, negative_pair, _ in tqdm(contrastive_dataloader):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        anchor = model(original_data.to(device)).logits\n",
    "        positive = model(positive_pair.to(device)).logits\n",
    "        negative = model(negative_pair.to(device)).logits\n",
    "        \n",
    "        # Compute the triplet loss\n",
    "        loss = triplet_loss(anchor, positive, negative)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "   #     print(loss.item())\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(contrastive_dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1f676",
   "metadata": {
    "cellId": "hotj0pa9xaanq47tsra14"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'contrastive_ozon.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47ab3a",
   "metadata": {
    "cellId": "13e01eam7vpcthi0zaphyes"
   },
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    y_idxs = []\n",
    "    y_embed = []\n",
    "    for orig, _, _, idx in tqdm(dataloader):\n",
    "        embed = model(orig.to(device))\n",
    "        y_idxs.extend([i.detach().cpu().item() for i in idx])\n",
    "        y_embed.extend([[j.item() for j in i.detach().cpu()] for i in embed])\n",
    "    return y_idxs, y_embed\n",
    "\n",
    "y_idxs, y_embed = predict(model, contrastive_dataloader)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf2567",
   "metadata": {
    "cellId": "z4kzqndgnndktzj920g70q"
   },
   "outputs": [],
   "source": [
    "embed = pd.DataFrame({'variant': y_idxs, 'embed': y_embed})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f7fdc",
   "metadata": {
    "cellId": "195zvarg628l1x0olm84qd"
   },
   "outputs": [],
   "source": [
    "classif = goods_pairs.merge(embed, left_on = 'variantid1', right_on = 'variant', how = 'left', suffixes = ['', '_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75151d8",
   "metadata": {
    "cellId": "amodnc3oyij5xn9u8y6uc9"
   },
   "outputs": [],
   "source": [
    "classif = classif.merge(embed, left_on = 'variantid2', right_on='variant', how = 'left', suffixes = ['', '_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d056fa1",
   "metadata": {
    "cellId": "9e5aihbdr5qvzuo9ubn6gb"
   },
   "outputs": [],
   "source": [
    "classif.drop(['variant', 'variant_2'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf62c02",
   "metadata": {
    "cellId": "hcw723qfepah22439a4xs"
   },
   "outputs": [],
   "source": [
    "classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28164fc7",
   "metadata": {
    "cellId": "nld2a2zp5weq2cet7njh8m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2998710",
   "metadata": {
    "cellId": "j1aa9a82h3qtziuq6fbj2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de868d18",
   "metadata": {
    "cellId": "1abg5mtuwxcnbngefc05j",
    "execution_id": "fbd4319c-4e57-4608-a722-d9abd711a9a7"
   },
   "source": [
    "# Catboost ingerence on cos sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f901a",
   "metadata": {
    "cellId": "2wqf0o2v7d5iyrru97wxg"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_pic_features(main_pic_embeddings_1,\n",
    "                     main_pic_embeddings_2,\n",
    "                     percentiles):\n",
    "    \"\"\"Calculate distances percentiles for \n",
    "    pairwise pic distances. Percentiles are useful \n",
    "    when product has several pictures.\n",
    "    \"\"\"\n",
    "    \n",
    "    if main_pic_embeddings_1 is not None and main_pic_embeddings_2 is not None:     \n",
    "        dist_m = cosine_similarity(\n",
    "            np.array(main_pic_embeddings_1)[None, ...], np.array(main_pic_embeddings_2)[None, ...]\n",
    "        )\n",
    "    else:\n",
    "        dist_m = np.array([[-1]])\n",
    "\n",
    "    pair_features = []\n",
    "    pair_features += np.percentile(dist_m, percentiles).tolist()\n",
    "\n",
    "    return pair_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a119d",
   "metadata": {
    "cellId": "tct1e10imbdcokud6ysnxv"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "classif = classif.dropna()\n",
    "get_pic_features_func = partial(\n",
    "    get_pic_features,\n",
    "    percentiles=[0, 25, 50]\n",
    ")\n",
    "classif[[\"pic_dist_0_perc\", \"pic_dist_25_perc\", \"pic_dist_50_perc\"]] = (\n",
    "    classif[[\"embed\", \"embed_2\"]].apply(\n",
    "        lambda x: pd.Series(get_pic_features_func(*x)), axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bc7cf",
   "metadata": {
    "cellId": "nvf773qmnnn8jb1oktvd"
   },
   "outputs": [],
   "source": [
    "classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e965f4d3",
   "metadata": {
    "cellId": "90rnd96ek8mtpmzgnp9koe"
   },
   "outputs": [],
   "source": [
    "classif = classif.merge(goods_data[['variantid', 'categories']], left_on = 'variantid1', right_on = 'variantid', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d260f7",
   "metadata": {
    "cellId": "bfg09qutjtkrx8tr3ng24"
   },
   "outputs": [],
   "source": [
    "classif[\"cat3\"] = classif[\"categories\"].apply(lambda x: json.loads(x)[\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca94923",
   "metadata": {
    "cellId": "pfeyjqpzxe880mg4bdih0i"
   },
   "outputs": [],
   "source": [
    "cat3_counts = classif[\"cat3\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48772de7",
   "metadata": {
    "cellId": "a9zgby4mxsgjye327lpwn"
   },
   "outputs": [],
   "source": [
    "classif[\"cat3_grouped\"] = classif[\"cat3\"].apply(lambda x: x if cat3_counts[x] > 1000 else \"rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02080a",
   "metadata": {
    "cellId": "sa70hpfgd9pzw3ie1dx24"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(\n",
    "    classif[['target', \"variantid1\", \"variantid2\", 'pic_dist_0_perc', 'cat3_grouped']], \n",
    "    test_size=0.1, random_state=42, stratify=classif[[\"target\", \"cat3_grouped\"]]\n",
    ")\n",
    "\n",
    "y_test = X_test[[\"target\", \"variantid1\", \"variantid2\" ]]\n",
    "X_test = X_test.drop([\"target\"], axis=1)\n",
    "\n",
    "y_train = X_train[\"target\"]\n",
    "\n",
    "X_train = X_train.drop([\"target\", \"variantid1\", \"variantid2\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437ee53",
   "metadata": {
    "cellId": "dn6sv2qaiegwfhb22kcnj"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e5a58",
   "metadata": {
    "cellId": "vkqmm35yd1otq7uax2so"
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier()\n",
    "\n",
    "model.fit(\n",
    "    X_train[['pic_dist_0_perc']], y_train,\n",
    "    plot=True,\n",
    "    verbose=True,\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=50,\n",
    "    metric_period=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2cc43",
   "metadata": {
    "cellId": "ujenqquk6yglnl5767b1vr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def pr_auc_macro(\n",
    "    target_df: pd.DataFrame,\n",
    "    predictions_df: pd.DataFrame,\n",
    "    prec_level: float = 0.75,\n",
    "    cat_column: str = \"cat3_grouped\"\n",
    ") -> float:\n",
    "    \n",
    "    df = target_df.merge(predictions_df, on=[\"variantid1\", \"variantid2\"])\n",
    "    \n",
    "    y_true = df[\"target\"]\n",
    "    y_pred = df[\"scores\"]\n",
    "    categories = df[cat_column]\n",
    "    \n",
    "    weights = []\n",
    "    pr_aucs = []\n",
    "\n",
    "    unique_cats, counts = np.unique(categories, return_counts=True)\n",
    "\n",
    "    for i, category in enumerate(unique_cats):\n",
    "        cat_idx = np.where(categories == category)[0]\n",
    "        y_pred_cat = y_pred[cat_idx]\n",
    "        y_true_cat = y_true[cat_idx]\n",
    "\n",
    "        y, x, thr = precision_recall_curve(y_true_cat, y_pred_cat)\n",
    "        gt_prec_level_idx = np.where(y >= prec_level)[0]\n",
    "\n",
    "        try:\n",
    "            pr_auc_prec_level = auc(x[gt_prec_level_idx], y[gt_prec_level_idx])\n",
    "            if not np.isnan(pr_auc_prec_level):\n",
    "                pr_aucs.append(pr_auc_prec_level)\n",
    "                weights.append(counts[i] / len(categories))\n",
    "        except ValueError as err:\n",
    "            pr_aucs.append(0)\n",
    "            weights.append(0)\n",
    "    return np.average(pr_aucs, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b837cc",
   "metadata": {
    "cellId": "ez1kwalfqrp1bixmsgb2ef"
   },
   "outputs": [],
   "source": [
    "X_test[\"scores\"] = model.predict_proba(X_test[['pic_dist_0_perc']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1dbdd4",
   "metadata": {
    "cellId": "xamyzmhydpn77llwgyhmzs"
   },
   "outputs": [],
   "source": [
    "pr_auc_macro_metr = pr_auc_macro(\n",
    "    target_df=y_test, \n",
    "    predictions_df=X_test,\n",
    "    prec_level=0.75,\n",
    "    cat_column=\"cat3_grouped\"\n",
    ")\n",
    "\n",
    "pr_auc_macro_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0aa68",
   "metadata": {
    "cellId": "qz6l3vbf9ecuudoju4fw2f"
   },
   "outputs": [],
   "source": [
    "#используется только одна картинка, можно делать positive pairs со всеми"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f62f5",
   "metadata": {
    "cellId": "lttw92q9kimmhlldkzki3j"
   },
   "outputs": [],
   "source": [
    "X_test[\"scores\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075f6c0",
   "metadata": {
    "cellId": "40s9wg88vsijj3w9k13e8"
   },
   "outputs": [],
   "source": [
    "#!c1.4\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "c08553f6-b795-4824-9df2-372951fb767c",
  "notebookPath": "ozon/Ozon_marketplace/bert_test.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
